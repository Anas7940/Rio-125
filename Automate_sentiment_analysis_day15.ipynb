{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "W-wUGv8srg4q"
      },
      "outputs": [],
      "source": [
        "import tarfile\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from gensim.models import Word2Vec"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDh-Nyu2sPzj",
        "outputId": "038538d7-3c7e-41cd-fc24-d3e553006502"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define file paths\n",
        "tar_file_path = '/content/drive/My Drive/aclImdb_v1.tar.gz'\n",
        "extracted_path = '/content/aclImdb'\n"
      ],
      "metadata": {
        "id": "PoztiOrKsS8B"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Extract tar file\n",
        "with tarfile.open(tar_file_path, 'r') as tar_ref:\n",
        "    tar_ref.extractall(extracted_path)"
      ],
      "metadata": {
        "id": "jHUozZr6sWko"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Directories for train and test data\n",
        "data_dir = os.path.join(extracted_path, 'aclImdb')\n",
        "train_dir = os.path.join(data_dir, 'train')\n",
        "test_dir = os.path.join(data_dir, 'test')\n"
      ],
      "metadata": {
        "id": "PP4ZDwFnsZGs"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data from directory\n",
        "def load_data_from_directory(directory):\n",
        "    texts = []\n",
        "    labels = []\n",
        "    for label_type in ['neg', 'pos']:\n",
        "        dir_name = os.path.join(directory, label_type)\n",
        "        for fname in os.listdir(dir_name):\n",
        "            if fname.endswith('.txt'):\n",
        "                with open(os.path.join(dir_name, fname), 'r', encoding='utf-8') as f:\n",
        "                    texts.append(f.read())\n",
        "                labels.append(0 if label_type == 'neg' else 1)\n",
        "    return texts, labels"
      ],
      "metadata": {
        "id": "8G_32aOvsbGI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load training and testing data\n",
        "train_texts, train_labels = load_data_from_directory(train_dir)\n",
        "test_texts, test_labels = load_data_from_directory(test_dir)"
      ],
      "metadata": {
        "id": "2lX6PsydsdXL"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create DataFrames for better visualization\n",
        "train_df = pd.DataFrame({'text': train_texts, 'label': train_labels})\n",
        "test_df = pd.DataFrame({'text': test_texts, 'label': test_labels})\n",
        "\n",
        "# Display first few rows of the DataFrames\n",
        "print(train_df.head())\n",
        "print(test_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LJ1c2WCKsgTT",
        "outputId": "8036538a-fd4b-4d1d-97e6-e7412545aeb6"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                text  label\n",
            "0  The plot of 7EVENTY 5IVE involves college kids...      0\n",
            "1  This movie was a mess. It had the absolute wor...      0\n",
            "2  This is definitely one of the weirder 70's mov...      0\n",
            "3  - A Mexican priest becomes a wrestler to save ...      0\n",
            "4  I saw the film tonight at a free preview scree...      0\n",
            "                                                text  label\n",
            "0  OK everybody is so enthused by this film I har...      0\n",
            "1  It beats me how anyone can rate this film very...      0\n",
            "2  First off, I saw another reviewer said this mo...      0\n",
            "3  OK, I've now seen George Zucco in at least fou...      0\n",
            "4  Spoof films have come so far since Mel Brooks ...      0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#  label distribution\n",
        "print(\"Training data label distribution:\")\n",
        "print(f\"Positive reviews: {np.sum(train_labels)}\")\n",
        "print(f\"Negative reviews: {len(train_labels) - np.sum(train_labels)}\")\n",
        "\n",
        "print(\"Testing data label distribution:\")\n",
        "print(f\"Positive reviews: {np.sum(test_labels)}\")\n",
        "print(f\"Negative reviews: {len(test_labels) - np.sum(test_labels)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bObWzH6fsji8",
        "outputId": "f4235bc7-192e-4893-c71f-5c7587393691"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data label distribution:\n",
            "Positive reviews: 12500\n",
            "Negative reviews: 12500\n",
            "Testing data label distribution:\n",
            "Positive reviews: 12500\n",
            "Negative reviews: 12500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenize text data\n",
        "max_features = 20000\n",
        "max_len = 250\n",
        "tokenizer = Tokenizer(num_words=max_features)\n",
        "tokenizer.fit_on_texts(train_texts)"
      ],
      "metadata": {
        "id": "kfLeiE5osmEd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert text to sequences of integers\n",
        "x_train = tokenizer.texts_to_sequences(train_texts)\n",
        "x_test = tokenizer.texts_to_sequences(test_texts)"
      ],
      "metadata": {
        "id": "wu1q3jC8soWT"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Pad sequences to ensure uniform input length\n",
        "x_train = pad_sequences(x_train, maxlen=max_len)\n",
        "x_test = pad_sequences(x_test, maxlen=max_len)\n"
      ],
      "metadata": {
        "id": "HtIPV08rsrFi"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numpy arrays\n",
        "y_train = np.array(train_labels)\n",
        "y_test = np.array(test_labels)"
      ],
      "metadata": {
        "id": "aL3uWgFFsuO5"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split training data into training and validation sets\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display data shapes\n",
        "print(\"Training data shape:\", x_train.shape)\n",
        "print(\"Validation data shape:\", x_val.shape)\n",
        "print(\"Test data shape:\", x_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yPZHqDiZswod",
        "outputId": "86823903-bab0-4ac1-a3fd-ce2982c76b90"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training data shape: (20000, 250)\n",
            "Validation data shape: (5000, 250)\n",
            "Test data shape: (25000, 250)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train a Word2Vec model\n",
        "sentences = [text.split() for text in train_texts]\n",
        "word2vec_model = Word2Vec(sentences, vector_size=100, window=5, min_count=1, workers=4)\n"
      ],
      "metadata": {
        "id": "FAb7yOdEs0SB"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create an embedding matrix\n",
        "word_index = tokenizer.word_index\n",
        "embedding_dim = 100\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, embedding_dim))\n",
        "for word, i in word_index.items():\n",
        "    if word in word2vec_model.wv:\n",
        "        embedding_matrix[i] = word2vec_model.wv[word]\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.normal(0, np.sqrt(0.25), embedding_dim)\n",
        "\n",
        "print(\"Word2Vec embedding matrix created.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwVRFAO6s24S",
        "outputId": "398a1d44-8d18-4693-dcaf-b691ffabce44"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Word2Vec embedding matrix created.\n"
          ]
        }
      ]
    }
  ]
}